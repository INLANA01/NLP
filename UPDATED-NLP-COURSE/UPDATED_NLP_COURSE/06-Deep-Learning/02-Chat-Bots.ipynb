{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___\n",
    "# Question and Answer Chat Bots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "We will be working with the Babi Data Set from Facebook Research.\n",
    "\n",
    "Full Details: https://research.fb.com/downloads/babi/\n",
    "\n",
    "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
    "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
    "  http://arxiv.org/abs/1502.05698\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    train_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question , answer in all_data:\n",
    "    # In case you don't know what a union of sets is:\n",
    "    # https://www.programiz.com/python-programming/methods/set/union\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bathroom': 1,\n",
       " 'john': 2,\n",
       " 'milk': 3,\n",
       " 'picked': 4,\n",
       " 'sandra': 5,\n",
       " 'the': 6,\n",
       " 'is': 7,\n",
       " 'to': 8,\n",
       " 'there': 9,\n",
       " 'kitchen': 10,\n",
       " 'journeyed': 11,\n",
       " 'up': 12,\n",
       " '?': 13,\n",
       " 'back': 14,\n",
       " 'down': 15,\n",
       " 'left': 16,\n",
       " 'football': 17,\n",
       " 'travelled': 18,\n",
       " 'took': 19,\n",
       " 'dropped': 20,\n",
       " 'garden': 21,\n",
       " 'mary': 22,\n",
       " 'went': 23,\n",
       " 'no': 24,\n",
       " 'moved': 25,\n",
       " 'discarded': 26,\n",
       " '.': 27,\n",
       " 'bedroom': 28,\n",
       " 'grabbed': 29,\n",
       " 'in': 30,\n",
       " 'got': 31,\n",
       " 'put': 32,\n",
       " 'office': 33,\n",
       " 'yes': 34,\n",
       " 'daniel': 35,\n",
       " 'hallway': 36,\n",
       " 'apple': 37}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        #\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  6, 28, 27],\n",
       "       [ 0,  0,  0, ...,  6, 21, 27],\n",
       "       [ 0,  0,  0, ...,  6, 21, 27],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  6, 37, 27],\n",
       "       [ 0,  0,  0, ...,  6, 21, 27],\n",
       "       [ 0,  0,  0, ..., 37,  9, 27]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  2, 30,  6, 10, 13],\n",
       "       [ 7,  2, 30,  6, 10, 13],\n",
       "       [ 7,  2, 30,  6, 21, 13],\n",
       "       ...,\n",
       "       [ 7, 22, 30,  6, 28, 13],\n",
       "       [ 7,  5, 30,  6, 21, 13],\n",
       "       [ 7, 22, 30,  6, 21, 13]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0., 503.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 497.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders for Inputs\n",
    "\n",
    "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1016 08:38:47.085358 33892 deprecation_wrapper.py:119] From C:\\Users\\adity\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1016 08:38:47.151151 33892 deprecation_wrapper.py:119] From C:\\Users\\adity\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Building the Networks\n",
    "\n",
    "To understand why we chose this setup, make sure to read the paper we are using:\n",
    "\n",
    "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  \"End-To-End Memory Networks\",\n",
    "  http://arxiv.org/abs/1503.08895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders\n",
    "\n",
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1016 08:38:52.956308 33892 deprecation_wrapper.py:119] From C:\\Users\\adity\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1016 08:38:52.996202 33892 deprecation_wrapper.py:119] From C:\\Users\\adity\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1016 08:38:53.015183 33892 deprecation.py:506] From C:\\Users\\adity\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_1/truediv:0' shape=(?, 156, 6) dtype=float32>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'sequential_3/dropout_3/cond/Merge:0' shape=(?, 156, 6) dtype=float32>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_encoded_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'sequential_1/dropout_1/cond/Merge:0' shape=(?, 156, 64) dtype=float32>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_encoded_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer = LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1016 12:11:16.355312 33892 deprecation_wrapper.py:119] From C:\\Users\\adity\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1016 12:11:16.507901 33892 deprecation_wrapper.py:119] From C:\\Users\\adity\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       multiple             2432        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_6 (Sequential)       (None, 6, 64)        2432        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 156, 6)       0           sequential_4[1][0]               \n",
      "                                                                 sequential_6[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 156, 6)       0           dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_5 (Sequential)       multiple             228         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 156, 6)       0           activation_3[0][0]               \n",
      "                                                                 sequential_5[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (None, 6, 156)       0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 6, 220)       0           permute_3[0][0]                  \n",
      "                                                                 sequential_6[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 32)           32384       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 38)           1254        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 38)           0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1016 12:11:19.796815 33892 deprecation.py:323] From C:\\Users\\adity\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "10000/10000 [==============================] - 10s 959us/step - loss: 0.9030 - acc: 0.4975 - val_loss: 0.6943 - val_acc: 0.5030\n",
      "Epoch 2/120\n",
      "10000/10000 [==============================] - 7s 710us/step - loss: 0.7031 - acc: 0.4976 - val_loss: 0.6973 - val_acc: 0.5030\n",
      "Epoch 3/120\n",
      "10000/10000 [==============================] - 7s 716us/step - loss: 0.6965 - acc: 0.4926 - val_loss: 0.6957 - val_acc: 0.5030\n",
      "Epoch 4/120\n",
      "10000/10000 [==============================] - 7s 716us/step - loss: 0.6951 - acc: 0.5019 - val_loss: 0.6936 - val_acc: 0.4970\n",
      "Epoch 5/120\n",
      "10000/10000 [==============================] - 7s 716us/step - loss: 0.6952 - acc: 0.4955 - val_loss: 0.6941 - val_acc: 0.4970\n",
      "Epoch 6/120\n",
      "10000/10000 [==============================] - 7s 718us/step - loss: 0.6941 - acc: 0.5078 - val_loss: 0.6932 - val_acc: 0.5030\n",
      "Epoch 7/120\n",
      "10000/10000 [==============================] - 7s 722us/step - loss: 0.6947 - acc: 0.4952 - val_loss: 0.6937 - val_acc: 0.4970\n",
      "Epoch 8/120\n",
      "10000/10000 [==============================] - 7s 720us/step - loss: 0.6940 - acc: 0.5075 - val_loss: 0.6943 - val_acc: 0.5030\n",
      "Epoch 9/120\n",
      "10000/10000 [==============================] - 7s 737us/step - loss: 0.6941 - acc: 0.5041 - val_loss: 0.6938 - val_acc: 0.5000\n",
      "Epoch 10/120\n",
      "10000/10000 [==============================] - 9s 880us/step - loss: 0.6942 - acc: 0.5004 - val_loss: 0.6944 - val_acc: 0.5020\n",
      "Epoch 11/120\n",
      "10000/10000 [==============================] - 9s 902us/step - loss: 0.6935 - acc: 0.5105 - val_loss: 0.6941 - val_acc: 0.4850\n",
      "Epoch 12/120\n",
      "10000/10000 [==============================] - 8s 844us/step - loss: 0.6925 - acc: 0.5119 - val_loss: 0.6934 - val_acc: 0.5220\n",
      "Epoch 13/120\n",
      "10000/10000 [==============================] - 8s 809us/step - loss: 0.6916 - acc: 0.5169 - val_loss: 0.6899 - val_acc: 0.4920\n",
      "Epoch 14/120\n",
      "10000/10000 [==============================] - 8s 803us/step - loss: 0.6855 - acc: 0.5410 - val_loss: 0.6812 - val_acc: 0.5430\n",
      "Epoch 15/120\n",
      "10000/10000 [==============================] - 9s 866us/step - loss: 0.6736 - acc: 0.5725 - val_loss: 0.6490 - val_acc: 0.6470\n",
      "Epoch 16/120\n",
      "10000/10000 [==============================] - 8s 805us/step - loss: 0.6541 - acc: 0.6158 - val_loss: 0.6347 - val_acc: 0.6450\n",
      "Epoch 17/120\n",
      "10000/10000 [==============================] - 9s 939us/step - loss: 0.6390 - acc: 0.6445 - val_loss: 0.6188 - val_acc: 0.6760\n",
      "Epoch 18/120\n",
      "10000/10000 [==============================] - 8s 792us/step - loss: 0.6281 - acc: 0.6639 - val_loss: 0.6158 - val_acc: 0.6770\n",
      "Epoch 19/120\n",
      "10000/10000 [==============================] - 7s 734us/step - loss: 0.6186 - acc: 0.6695 - val_loss: 0.6060 - val_acc: 0.6860\n",
      "Epoch 20/120\n",
      "10000/10000 [==============================] - 8s 775us/step - loss: 0.6203 - acc: 0.6733 - val_loss: 0.6035 - val_acc: 0.6900\n",
      "Epoch 21/120\n",
      "10000/10000 [==============================] - 7s 736us/step - loss: 0.6123 - acc: 0.6809 - val_loss: 0.5972 - val_acc: 0.6950\n",
      "Epoch 22/120\n",
      "10000/10000 [==============================] - 7s 714us/step - loss: 0.6087 - acc: 0.6852 - val_loss: 0.6000 - val_acc: 0.6890\n",
      "Epoch 23/120\n",
      "10000/10000 [==============================] - 7s 728us/step - loss: 0.5998 - acc: 0.6922 - val_loss: 0.5906 - val_acc: 0.7040\n",
      "Epoch 24/120\n",
      "10000/10000 [==============================] - 7s 735us/step - loss: 0.5968 - acc: 0.6915 - val_loss: 0.5886 - val_acc: 0.6880\n",
      "Epoch 25/120\n",
      "10000/10000 [==============================] - 7s 739us/step - loss: 0.5901 - acc: 0.7001 - val_loss: 0.5795 - val_acc: 0.7020\n",
      "Epoch 26/120\n",
      "10000/10000 [==============================] - 7s 716us/step - loss: 0.5876 - acc: 0.7006 - val_loss: 0.5758 - val_acc: 0.7090\n",
      "Epoch 27/120\n",
      "10000/10000 [==============================] - 7s 718us/step - loss: 0.5796 - acc: 0.7058 - val_loss: 0.5849 - val_acc: 0.6830\n",
      "Epoch 28/120\n",
      "10000/10000 [==============================] - 7s 736us/step - loss: 0.5712 - acc: 0.7159 - val_loss: 0.5598 - val_acc: 0.7050\n",
      "Epoch 29/120\n",
      "10000/10000 [==============================] - 7s 745us/step - loss: 0.5518 - acc: 0.7295 - val_loss: 0.5335 - val_acc: 0.7540\n",
      "Epoch 30/120\n",
      "10000/10000 [==============================] - 7s 715us/step - loss: 0.5333 - acc: 0.7447 - val_loss: 0.5154 - val_acc: 0.7560\n",
      "Epoch 31/120\n",
      "10000/10000 [==============================] - 7s 724us/step - loss: 0.5218 - acc: 0.7583 - val_loss: 0.4942 - val_acc: 0.7700\n",
      "Epoch 32/120\n",
      "10000/10000 [==============================] - 7s 697us/step - loss: 0.4988 - acc: 0.7705 - val_loss: 0.4852 - val_acc: 0.7730\n",
      "Epoch 33/120\n",
      "10000/10000 [==============================] - 7s 699us/step - loss: 0.4809 - acc: 0.7776 - val_loss: 0.4853 - val_acc: 0.7700\n",
      "Epoch 34/120\n",
      "10000/10000 [==============================] - 7s 695us/step - loss: 0.4758 - acc: 0.7828 - val_loss: 0.4555 - val_acc: 0.7840\n",
      "Epoch 35/120\n",
      "10000/10000 [==============================] - 7s 701us/step - loss: 0.4583 - acc: 0.7945 - val_loss: 0.4396 - val_acc: 0.7910\n",
      "Epoch 36/120\n",
      "10000/10000 [==============================] - 7s 689us/step - loss: 0.4534 - acc: 0.7938 - val_loss: 0.4534 - val_acc: 0.7840\n",
      "Epoch 37/120\n",
      "10000/10000 [==============================] - 7s 693us/step - loss: 0.4452 - acc: 0.7976 - val_loss: 0.4445 - val_acc: 0.7950\n",
      "Epoch 38/120\n",
      "10000/10000 [==============================] - 7s 703us/step - loss: 0.4333 - acc: 0.8033 - val_loss: 0.4412 - val_acc: 0.7940\n",
      "Epoch 39/120\n",
      "10000/10000 [==============================] - 7s 688us/step - loss: 0.4305 - acc: 0.8097 - val_loss: 0.4475 - val_acc: 0.7840\n",
      "Epoch 40/120\n",
      "10000/10000 [==============================] - 7s 683us/step - loss: 0.4278 - acc: 0.8077 - val_loss: 0.4338 - val_acc: 0.8010\n",
      "Epoch 41/120\n",
      "10000/10000 [==============================] - 7s 686us/step - loss: 0.4224 - acc: 0.8076 - val_loss: 0.4265 - val_acc: 0.7990\n",
      "Epoch 42/120\n",
      "10000/10000 [==============================] - 7s 688us/step - loss: 0.4212 - acc: 0.8078 - val_loss: 0.4239 - val_acc: 0.8030\n",
      "Epoch 43/120\n",
      "10000/10000 [==============================] - 7s 685us/step - loss: 0.4144 - acc: 0.8156 - val_loss: 0.4363 - val_acc: 0.8050\n",
      "Epoch 44/120\n",
      "10000/10000 [==============================] - 7s 687us/step - loss: 0.4100 - acc: 0.8213 - val_loss: 0.4285 - val_acc: 0.8000\n",
      "Epoch 45/120\n",
      "10000/10000 [==============================] - 7s 696us/step - loss: 0.4126 - acc: 0.8160 - val_loss: 0.4296 - val_acc: 0.8040\n",
      "Epoch 46/120\n",
      "10000/10000 [==============================] - 7s 726us/step - loss: 0.4027 - acc: 0.8239 - val_loss: 0.4341 - val_acc: 0.8100\n",
      "Epoch 47/120\n",
      "10000/10000 [==============================] - 7s 669us/step - loss: 0.4035 - acc: 0.8214 - val_loss: 0.4189 - val_acc: 0.8090\n",
      "Epoch 48/120\n",
      "10000/10000 [==============================] - 7s 723us/step - loss: 0.3977 - acc: 0.8278 - val_loss: 0.4235 - val_acc: 0.8070\n",
      "Epoch 49/120\n",
      "10000/10000 [==============================] - 7s 689us/step - loss: 0.3954 - acc: 0.8247 - val_loss: 0.4302 - val_acc: 0.8020\n",
      "Epoch 50/120\n",
      "10000/10000 [==============================] - 7s 704us/step - loss: 0.3951 - acc: 0.8286 - val_loss: 0.4193 - val_acc: 0.8080\n",
      "Epoch 51/120\n",
      "10000/10000 [==============================] - 7s 713us/step - loss: 0.3820 - acc: 0.8319 - val_loss: 0.4284 - val_acc: 0.8040\n",
      "Epoch 52/120\n",
      "10000/10000 [==============================] - 7s 703us/step - loss: 0.3796 - acc: 0.8356 - val_loss: 0.4207 - val_acc: 0.8020\n",
      "Epoch 53/120\n",
      "10000/10000 [==============================] - 7s 700us/step - loss: 0.3793 - acc: 0.8337 - val_loss: 0.4229 - val_acc: 0.8060\n",
      "Epoch 54/120\n",
      "10000/10000 [==============================] - 7s 721us/step - loss: 0.3705 - acc: 0.8366 - val_loss: 0.4194 - val_acc: 0.8120\n",
      "Epoch 55/120\n",
      "10000/10000 [==============================] - 7s 746us/step - loss: 0.3717 - acc: 0.8381 - val_loss: 0.4065 - val_acc: 0.8130\n",
      "Epoch 56/120\n",
      "10000/10000 [==============================] - 7s 743us/step - loss: 0.3628 - acc: 0.8441 - val_loss: 0.4302 - val_acc: 0.8010\n",
      "Epoch 57/120\n",
      "10000/10000 [==============================] - 7s 702us/step - loss: 0.3595 - acc: 0.8457 - val_loss: 0.4251 - val_acc: 0.8030\n",
      "Epoch 58/120\n",
      "10000/10000 [==============================] - 7s 711us/step - loss: 0.3550 - acc: 0.8496 - val_loss: 0.4237 - val_acc: 0.8070\n",
      "Epoch 59/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s 662us/step - loss: 0.3511 - acc: 0.8483 - val_loss: 0.4258 - val_acc: 0.8140\n",
      "Epoch 60/120\n",
      "10000/10000 [==============================] - 6s 645us/step - loss: 0.3515 - acc: 0.8542 - val_loss: 0.4134 - val_acc: 0.8090\n",
      "Epoch 61/120\n",
      "10000/10000 [==============================] - 7s 671us/step - loss: 0.3432 - acc: 0.8493 - val_loss: 0.4184 - val_acc: 0.8190\n",
      "Epoch 62/120\n",
      "10000/10000 [==============================] - 7s 695us/step - loss: 0.3322 - acc: 0.8602 - val_loss: 0.4098 - val_acc: 0.82606 - acc: \n",
      "Epoch 63/120\n",
      "10000/10000 [==============================] - 7s 652us/step - loss: 0.3292 - acc: 0.8606 - val_loss: 0.4064 - val_acc: 0.8270\n",
      "Epoch 64/120\n",
      "10000/10000 [==============================] - 7s 689us/step - loss: 0.3304 - acc: 0.8577 - val_loss: 0.4390 - val_acc: 0.8150\n",
      "Epoch 65/120\n",
      "10000/10000 [==============================] - 7s 739us/step - loss: 0.3336 - acc: 0.8581 - val_loss: 0.4130 - val_acc: 0.8200\n",
      "Epoch 66/120\n",
      "10000/10000 [==============================] - 8s 779us/step - loss: 0.3270 - acc: 0.8626 - val_loss: 0.4177 - val_acc: 0.8180\n",
      "Epoch 67/120\n",
      "10000/10000 [==============================] - 7s 690us/step - loss: 0.3235 - acc: 0.8619 - val_loss: 0.4047 - val_acc: 0.8220\n",
      "Epoch 68/120\n",
      "10000/10000 [==============================] - 8s 773us/step - loss: 0.3190 - acc: 0.8645 - val_loss: 0.4469 - val_acc: 0.8050\n",
      "Epoch 69/120\n",
      "10000/10000 [==============================] - 7s 737us/step - loss: 0.3140 - acc: 0.8685 - val_loss: 0.3985 - val_acc: 0.8280\n",
      "Epoch 70/120\n",
      "10000/10000 [==============================] - 7s 699us/step - loss: 0.3161 - acc: 0.8677 - val_loss: 0.4242 - val_acc: 0.8230\n",
      "Epoch 71/120\n",
      "10000/10000 [==============================] - 7s 657us/step - loss: 0.3108 - acc: 0.8702 - val_loss: 0.4181 - val_acc: 0.8260\n",
      "Epoch 72/120\n",
      "10000/10000 [==============================] - 7s 689us/step - loss: 0.3099 - acc: 0.8682 - val_loss: 0.4134 - val_acc: 0.8270\n",
      "Epoch 73/120\n",
      "10000/10000 [==============================] - 7s 717us/step - loss: 0.2989 - acc: 0.8736 - val_loss: 0.4224 - val_acc: 0.8230\n",
      "Epoch 74/120\n",
      "10000/10000 [==============================] - 7s 739us/step - loss: 0.3083 - acc: 0.8695 - val_loss: 0.4368 - val_acc: 0.8220\n",
      "Epoch 75/120\n",
      "10000/10000 [==============================] - 7s 662us/step - loss: 0.2996 - acc: 0.8736 - val_loss: 0.4626 - val_acc: 0.8240\n",
      "Epoch 76/120\n",
      "10000/10000 [==============================] - 7s 655us/step - loss: 0.2929 - acc: 0.8758 - val_loss: 0.4377 - val_acc: 0.8230\n",
      "Epoch 77/120\n",
      "10000/10000 [==============================] - 7s 702us/step - loss: 0.2951 - acc: 0.8776 - val_loss: 0.4460 - val_acc: 0.8090\n",
      "Epoch 78/120\n",
      "10000/10000 [==============================] - 8s 779us/step - loss: 0.2920 - acc: 0.8813 - val_loss: 0.4570 - val_acc: 0.8190\n",
      "Epoch 79/120\n",
      "10000/10000 [==============================] - 7s 678us/step - loss: 0.2868 - acc: 0.8762 - val_loss: 0.4713 - val_acc: 0.8230\n",
      "Epoch 80/120\n",
      "10000/10000 [==============================] - 7s 675us/step - loss: 0.2869 - acc: 0.8791 - val_loss: 0.4651 - val_acc: 0.8210\n",
      "Epoch 81/120\n",
      "10000/10000 [==============================] - 6s 647us/step - loss: 0.2871 - acc: 0.8791 - val_loss: 0.4659 - val_acc: 0.8130\n",
      "Epoch 82/120\n",
      "10000/10000 [==============================] - 7s 687us/step - loss: 0.2786 - acc: 0.8841 - val_loss: 0.4633 - val_acc: 0.8190\n",
      "Epoch 83/120\n",
      "10000/10000 [==============================] - 7s 676us/step - loss: 0.2787 - acc: 0.8850 - val_loss: 0.4397 - val_acc: 0.8190\n",
      "Epoch 84/120\n",
      "10000/10000 [==============================] - 6s 647us/step - loss: 0.2765 - acc: 0.8834 - val_loss: 0.4579 - val_acc: 0.8280 - loss: 0.2785\n",
      "Epoch 85/120\n",
      "10000/10000 [==============================] - 6s 637us/step - loss: 0.2798 - acc: 0.8837 - val_loss: 0.4557 - val_acc: 0.8110\n",
      "Epoch 86/120\n",
      "10000/10000 [==============================] - 7s 658us/step - loss: 0.2749 - acc: 0.8849 - val_loss: 0.4404 - val_acc: 0.8170\n",
      "Epoch 87/120\n",
      "10000/10000 [==============================] - 7s 650us/step - loss: 0.2710 - acc: 0.8843 - val_loss: 0.4410 - val_acc: 0.8270\n",
      "Epoch 88/120\n",
      "10000/10000 [==============================] - 7s 666us/step - loss: 0.2692 - acc: 0.8905 - val_loss: 0.4586 - val_acc: 0.8240\n",
      "Epoch 89/120\n",
      "10000/10000 [==============================] - 7s 703us/step - loss: 0.2701 - acc: 0.8888 - val_loss: 0.4756 - val_acc: 0.8120\n",
      "Epoch 90/120\n",
      "10000/10000 [==============================] - 6s 621us/step - loss: 0.2709 - acc: 0.8876 - val_loss: 0.4510 - val_acc: 0.8250\n",
      "Epoch 91/120\n",
      "10000/10000 [==============================] - 6s 620us/step - loss: 0.2641 - acc: 0.8908 - val_loss: 0.4902 - val_acc: 0.8160\n",
      "Epoch 92/120\n",
      "10000/10000 [==============================] - 6s 625us/step - loss: 0.2638 - acc: 0.8880 - val_loss: 0.4871 - val_acc: 0.8190\n",
      "Epoch 93/120\n",
      "10000/10000 [==============================] - 7s 669us/step - loss: 0.2616 - acc: 0.8912 - val_loss: 0.4992 - val_acc: 0.8050\n",
      "Epoch 94/120\n",
      "10000/10000 [==============================] - 7s 681us/step - loss: 0.2591 - acc: 0.8959 - val_loss: 0.4939 - val_acc: 0.8240 - acc: 0.\n",
      "Epoch 95/120\n",
      "10000/10000 [==============================] - 7s 651us/step - loss: 0.2630 - acc: 0.8898 - val_loss: 0.4925 - val_acc: 0.8210\n",
      "Epoch 96/120\n",
      "10000/10000 [==============================] - 6s 648us/step - loss: 0.2602 - acc: 0.8913 - val_loss: 0.4751 - val_acc: 0.8240\n",
      "Epoch 97/120\n",
      "10000/10000 [==============================] - 7s 717us/step - loss: 0.2553 - acc: 0.8979 - val_loss: 0.5157 - val_acc: 0.8080\n",
      "Epoch 98/120\n",
      "10000/10000 [==============================] - 7s 699us/step - loss: 0.2519 - acc: 0.8966 - val_loss: 0.4937 - val_acc: 0.8130\n",
      "Epoch 99/120\n",
      "10000/10000 [==============================] - 7s 701us/step - loss: 0.2560 - acc: 0.8934 - val_loss: 0.5191 - val_acc: 0.8070\n",
      "Epoch 100/120\n",
      "10000/10000 [==============================] - 7s 742us/step - loss: 0.2447 - acc: 0.9005 - val_loss: 0.4744 - val_acc: 0.8210\n",
      "Epoch 101/120\n",
      "10000/10000 [==============================] - 7s 749us/step - loss: 0.2492 - acc: 0.8972 - val_loss: 0.5806 - val_acc: 0.8010\n",
      "Epoch 102/120\n",
      "10000/10000 [==============================] - 7s 682us/step - loss: 0.2466 - acc: 0.8980 - val_loss: 0.5151 - val_acc: 0.7990s - loss - \n",
      "Epoch 103/120\n",
      "10000/10000 [==============================] - 8s 751us/step - loss: 0.2453 - acc: 0.8998 - val_loss: 0.5367 - val_acc: 0.8050\n",
      "Epoch 104/120\n",
      "10000/10000 [==============================] - 7s 654us/step - loss: 0.2423 - acc: 0.8996 - val_loss: 0.5445 - val_acc: 0.8190\n",
      "Epoch 105/120\n",
      "10000/10000 [==============================] - 7s 655us/step - loss: 0.2407 - acc: 0.8987 - val_loss: 0.5436 - val_acc: 0.8150\n",
      "Epoch 106/120\n",
      "10000/10000 [==============================] - 6s 649us/step - loss: 0.2445 - acc: 0.8973 - val_loss: 0.5498 - val_acc: 0.8080\n",
      "Epoch 107/120\n",
      "10000/10000 [==============================] - 7s 688us/step - loss: 0.2456 - acc: 0.9008 - val_loss: 0.4962 - val_acc: 0.8120\n",
      "Epoch 108/120\n",
      "10000/10000 [==============================] - 6s 614us/step - loss: 0.2410 - acc: 0.9052 - val_loss: 0.5035 - val_acc: 0.8210\n",
      "Epoch 109/120\n",
      "10000/10000 [==============================] - 6s 606us/step - loss: 0.2352 - acc: 0.9054 - val_loss: 0.5368 - val_acc: 0.8160\n",
      "Epoch 110/120\n",
      "10000/10000 [==============================] - 6s 621us/step - loss: 0.2397 - acc: 0.9033 - val_loss: 0.5433 - val_acc: 0.8070\n",
      "Epoch 111/120\n",
      "10000/10000 [==============================] - 6s 607us/step - loss: 0.2271 - acc: 0.9076 - val_loss: 0.5472 - val_acc: 0.8120\n",
      "Epoch 112/120\n",
      "10000/10000 [==============================] - 7s 664us/step - loss: 0.2340 - acc: 0.9052 - val_loss: 0.5667 - val_acc: 0.8090\n",
      "Epoch 113/120\n",
      "10000/10000 [==============================] - 6s 604us/step - loss: 0.2322 - acc: 0.9076 - val_loss: 0.5616 - val_acc: 0.8040\n",
      "Epoch 114/120\n",
      "10000/10000 [==============================] - 6s 607us/step - loss: 0.2288 - acc: 0.9075 - val_loss: 0.5469 - val_acc: 0.8150\n",
      "Epoch 115/120\n",
      "10000/10000 [==============================] - 6s 602us/step - loss: 0.2221 - acc: 0.9102 - val_loss: 0.5619 - val_acc: 0.8070oss: 0.2204 - a\n",
      "Epoch 116/120\n",
      "10000/10000 [==============================] - 6s 605us/step - loss: 0.2253 - acc: 0.9101 - val_loss: 0.5633 - val_acc: 0.8080\n",
      "Epoch 117/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 607us/step - loss: 0.2265 - acc: 0.9098 - val_loss: 0.5068 - val_acc: 0.8120\n",
      "Epoch 118/120\n",
      "10000/10000 [==============================] - 6s 640us/step - loss: 0.2317 - acc: 0.9067 - val_loss: 0.5538 - val_acc: 0.8030\n",
      "Epoch 119/120\n",
      "10000/10000 [==============================] - 7s 663us/step - loss: 0.2200 - acc: 0.9124 - val_loss: 0.6445 - val_acc: 0.7950\n",
      "Epoch 120/120\n",
      "10000/10000 [==============================] - 6s 638us/step - loss: 0.2224 - acc: 0.9107 - val_loss: 0.5515 - val_acc: 0.8160\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'chatbot_120_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "### Plotting Out Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on Given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.98829496\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Your Own Stories and Questions\n",
    "\n",
    "Remember you can only use words from the existing vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the whitespace of the periods\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.89005244\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
