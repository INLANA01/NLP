{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_qa.txt','rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_qa.txt','rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(train_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for story,question,answer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_story_lens = [len(data[0]) for data in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max(all_story_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras_preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answer_text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "    train_answer_text.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index = tokenizer.word_index,max_story_len= max_story_len,max_question_len=max_question_len ):\n",
    "    # Stories = X\n",
    "    X = []\n",
    "    # Questions Xq\n",
    "    Xq = []\n",
    "    # Correct Answer (yes/no)\n",
    "    Y = []\n",
    "    \n",
    "    for story,query,answer in data:\n",
    "        # for each story\n",
    "        # [23,14,...]\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    return (pad_sequences(X,maxlen = max_story_len),pad_sequences(Xq,maxlen = max_question_len),np.array(Y))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answer_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answer_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 29, 36, 12],\n",
       "       [ 0,  0,  0, ..., 29, 11, 12],\n",
       "       [ 0,  0,  0, ..., 29, 11, 12],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 29, 16, 12],\n",
       "       [ 0,  0,  0, ..., 29, 11, 12],\n",
       "       [ 0,  0,  0, ..., 16, 23, 12]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0., 497.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 503.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answer_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDER shape  = (max_story_len, batch_size)\n",
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_len\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT ENCODER M\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim = vocab_size, output_dim = 64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "#OUTPUT\n",
    "# (samples, ,story_maxLen, max_question_Len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT ENCODER C\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim = vocab_size, output_dim = max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "\n",
    "#OUTPUT\n",
    "# (samples,story_maxLen, max_question_Len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "\n",
    "# (Samples, query_maxLen, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODED <---- ENCODER(INPUT)\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = dot([input_encoded_m, question_encoded], axes=(2,2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = add([match,input_encoded_c])\n",
    "response = Permute((2,1))(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = LSTM(32)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input_sequence, question], answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 22:37:25.897707 20284 deprecation_wrapper.py:119] From C:\\Users\\adity\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0909 22:37:25.923669 20284 deprecation_wrapper.py:119] From C:\\Users\\adity\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       multiple             2432        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       (None, 6, 64)        2432        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_4 (Dot)                     (None, 156, 6)       0           sequential_4[2][0]               \n",
      "                                                                 sequential_8[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 156, 6)       0           dot_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_7 (Sequential)       multiple             228         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 156, 6)       0           activation_4[0][0]               \n",
      "                                                                 sequential_7[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_8[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 23:21:12.272950 20284 deprecation.py:323] From C:\\Users\\adity\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.8690 - acc: 0.5054 - val_loss: 0.6966 - val_acc: 0.4970\n",
      "Epoch 2/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.7003 - acc: 0.5059 - val_loss: 0.6934 - val_acc: 0.4970\n",
      "Epoch 3/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6957 - acc: 0.5027 - val_loss: 0.6940 - val_acc: 0.4970\n",
      "Epoch 4/120\n",
      "10000/10000 [==============================] - 8s 769us/step - loss: 0.6947 - acc: 0.5001 - val_loss: 0.6978 - val_acc: 0.4970\n",
      "Epoch 5/120\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.6941 - acc: 0.5005 - val_loss: 0.6939 - val_acc: 0.4970\n",
      "Epoch 6/120\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.6954 - acc: 0.4916 - val_loss: 0.6933 - val_acc: 0.4970loss: 0.6955 - acc: 0 - ETA: 2s - loss: 0.6954 - acc: 0 - ETA: 1s - loss: 0.6953 - \n",
      "Epoch 7/120\n",
      "10000/10000 [==============================] - 8s 760us/step - loss: 0.6945 - acc: 0.5043 - val_loss: 0.6934 - val_acc: 0.5030\n",
      "Epoch 8/120\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.6939 - acc: 0.5076 - val_loss: 0.6933 - val_acc: 0.5030\n",
      "Epoch 9/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.6943 - acc: 0.4984 - val_loss: 0.6936 - val_acc: 0.4900\n",
      "Epoch 10/120\n",
      "10000/10000 [==============================] - 8s 762us/step - loss: 0.6940 - acc: 0.5010 - val_loss: 0.6935 - val_acc: 0.4970\n",
      "Epoch 11/120\n",
      "10000/10000 [==============================] - 8s 773us/step - loss: 0.6940 - acc: 0.5057 - val_loss: 0.6946 - val_acc: 0.4970\n",
      "Epoch 12/120\n",
      "10000/10000 [==============================] - 9s 897us/step - loss: 0.6940 - acc: 0.5021 - val_loss: 0.6937 - val_acc: 0.5030\n",
      "Epoch 13/120\n",
      "10000/10000 [==============================] - 9s 947us/step - loss: 0.6934 - acc: 0.5110 - val_loss: 0.6953 - val_acc: 0.5040\n",
      "Epoch 14/120\n",
      "10000/10000 [==============================] - 10s 976us/step - loss: 0.6936 - acc: 0.5105 - val_loss: 0.6971 - val_acc: 0.4970\n",
      "Epoch 15/120\n",
      "10000/10000 [==============================] - 9s 899us/step - loss: 0.6933 - acc: 0.5121 - val_loss: 0.6951 - val_acc: 0.5130\n",
      "Epoch 16/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.6931 - acc: 0.5117 - val_loss: 0.6955 - val_acc: 0.4800\n",
      "Epoch 17/120\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.6922 - acc: 0.5204 - val_loss: 0.6957 - val_acc: 0.4950\n",
      "Epoch 18/120\n",
      "10000/10000 [==============================] - 8s 755us/step - loss: 0.6904 - acc: 0.5289 - val_loss: 0.6945 - val_acc: 0.5280\n",
      "Epoch 19/120\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.6847 - acc: 0.5482 - val_loss: 0.6775 - val_acc: 0.5810\n",
      "Epoch 20/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.6419 - acc: 0.6304 - val_loss: 0.5765 - val_acc: 0.7190\n",
      "Epoch 21/120\n",
      "10000/10000 [==============================] - 8s 775us/step - loss: 0.5615 - acc: 0.7205 - val_loss: 0.4816 - val_acc: 0.7760\n",
      "Epoch 22/120\n",
      "10000/10000 [==============================] - 7s 744us/step - loss: 0.5207 - acc: 0.7586 - val_loss: 0.4712 - val_acc: 0.7720\n",
      "Epoch 23/120\n",
      "10000/10000 [==============================] - 8s 755us/step - loss: 0.4970 - acc: 0.7741 - val_loss: 0.4434 - val_acc: 0.7950\n",
      "Epoch 24/120\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.4756 - acc: 0.7905 - val_loss: 0.4438 - val_acc: 0.8000\n",
      "Epoch 25/120\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.4630 - acc: 0.7948 - val_loss: 0.4474 - val_acc: 0.8000\n",
      "Epoch 26/120\n",
      "10000/10000 [==============================] - 8s 774us/step - loss: 0.4513 - acc: 0.7963 - val_loss: 0.4430 - val_acc: 0.8160\n",
      "Epoch 27/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.4438 - acc: 0.8010 - val_loss: 0.4438 - val_acc: 0.8050\n",
      "Epoch 28/120\n",
      "10000/10000 [==============================] - 8s 764us/step - loss: 0.4305 - acc: 0.8087 - val_loss: 0.4249 - val_acc: 0.8080\n",
      "Epoch 29/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.4228 - acc: 0.8174 - val_loss: 0.4236 - val_acc: 0.8100\n",
      "Epoch 30/120\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.4118 - acc: 0.8194 - val_loss: 0.4221 - val_acc: 0.8120\n",
      "Epoch 31/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.4041 - acc: 0.8256 - val_loss: 0.4030 - val_acc: 0.8100\n",
      "Epoch 32/120\n",
      "10000/10000 [==============================] - 7s 713us/step - loss: 0.3962 - acc: 0.8262 - val_loss: 0.4021 - val_acc: 0.8210\n",
      "Epoch 33/120\n",
      "10000/10000 [==============================] - 5s 495us/step - loss: 0.3832 - acc: 0.8363 - val_loss: 0.4008 - val_acc: 0.8180\n",
      "Epoch 34/120\n",
      "10000/10000 [==============================] - 5s 519us/step - loss: 0.3733 - acc: 0.8424 - val_loss: 0.4073 - val_acc: 0.8060\n",
      "Epoch 35/120\n",
      "10000/10000 [==============================] - 4s 437us/step - loss: 0.3704 - acc: 0.8449 - val_loss: 0.3972 - val_acc: 0.8380\n",
      "Epoch 36/120\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.3651 - acc: 0.8513 - val_loss: 0.3850 - val_acc: 0.8240\n",
      "Epoch 37/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3612 - acc: 0.8470 - val_loss: 0.3736 - val_acc: 0.8410\n",
      "Epoch 38/120\n",
      "10000/10000 [==============================] - 6s 640us/step - loss: 0.3561 - acc: 0.8533 - val_loss: 0.3999 - val_acc: 0.8340\n",
      "Epoch 39/120\n",
      "10000/10000 [==============================] - 5s 504us/step - loss: 0.3467 - acc: 0.8552 - val_loss: 0.3810 - val_acc: 0.8330\n",
      "Epoch 40/120\n",
      "10000/10000 [==============================] - 5s 513us/step - loss: 0.3472 - acc: 0.8542 - val_loss: 0.3954 - val_acc: 0.8350\n",
      "Epoch 41/120\n",
      "10000/10000 [==============================] - 6s 608us/step - loss: 0.3409 - acc: 0.8536 - val_loss: 0.3771 - val_acc: 0.8400\n",
      "Epoch 42/120\n",
      "10000/10000 [==============================] - 4s 431us/step - loss: 0.3378 - acc: 0.8593 - val_loss: 0.3768 - val_acc: 0.8250\n",
      "Epoch 43/120\n",
      "10000/10000 [==============================] - 6s 647us/step - loss: 0.3409 - acc: 0.8575 - val_loss: 0.3730 - val_acc: 0.8260\n",
      "Epoch 44/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.3391 - acc: 0.8571 - val_loss: 0.3655 - val_acc: 0.8280\n",
      "Epoch 45/120\n",
      "10000/10000 [==============================] - 10s 979us/step - loss: 0.3370 - acc: 0.8575 - val_loss: 0.3654 - val_acc: 0.8330\n",
      "Epoch 46/120\n",
      "10000/10000 [==============================] - 6s 594us/step - loss: 0.3321 - acc: 0.8597 - val_loss: 0.3804 - val_acc: 0.8340\n",
      "Epoch 47/120\n",
      "10000/10000 [==============================] - 5s 495us/step - loss: 0.3292 - acc: 0.8611 - val_loss: 0.3734 - val_acc: 0.8370\n",
      "Epoch 48/120\n",
      "10000/10000 [==============================] - 4s 401us/step - loss: 0.3196 - acc: 0.8647 - val_loss: 0.3751 - val_acc: 0.8310\n",
      "Epoch 49/120\n",
      "10000/10000 [==============================] - 5s 506us/step - loss: 0.3255 - acc: 0.8613 - val_loss: 0.3704 - val_acc: 0.8320\n",
      "Epoch 50/120\n",
      "10000/10000 [==============================] - 5s 522us/step - loss: 0.3215 - acc: 0.8651 - val_loss: 0.3839 - val_acc: 0.8360\n",
      "Epoch 51/120\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.3246 - acc: 0.8605 - val_loss: 0.3803 - val_acc: 0.8260\n",
      "Epoch 52/120\n",
      "10000/10000 [==============================] - 5s 537us/step - loss: 0.3194 - acc: 0.8620 - val_loss: 0.4002 - val_acc: 0.8270\n",
      "Epoch 53/120\n",
      "10000/10000 [==============================] - 7s 667us/step - loss: 0.3175 - acc: 0.8643 - val_loss: 0.3817 - val_acc: 0.8230- ETA: 0s - loss: 0.3173 \n",
      "Epoch 54/120\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.3117 - acc: 0.8691 - val_loss: 0.3730 - val_acc: 0.8340\n",
      "Epoch 55/120\n",
      "10000/10000 [==============================] - 5s 517us/step - loss: 0.3128 - acc: 0.8702 - val_loss: 0.4058 - val_acc: 0.8170\n",
      "Epoch 56/120\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.3100 - acc: 0.8661 - val_loss: 0.3739 - val_acc: 0.8350\n",
      "Epoch 57/120\n",
      "10000/10000 [==============================] - 5s 533us/step - loss: 0.3113 - acc: 0.8682 - val_loss: 0.3699 - val_acc: 0.8270\n",
      "Epoch 58/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 466us/step - loss: 0.3088 - acc: 0.8674 - val_loss: 0.3765 - val_acc: 0.8320\n",
      "Epoch 59/120\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.3088 - acc: 0.8682 - val_loss: 0.3781 - val_acc: 0.8230\n",
      "Epoch 60/120\n",
      "10000/10000 [==============================] - 5s 511us/step - loss: 0.3004 - acc: 0.8711 - val_loss: 0.3948 - val_acc: 0.8280\n",
      "Epoch 61/120\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.3003 - acc: 0.8728 - val_loss: 0.3933 - val_acc: 0.8200\n",
      "Epoch 62/120\n",
      "10000/10000 [==============================] - 5s 541us/step - loss: 0.2977 - acc: 0.8742 - val_loss: 0.4032 - val_acc: 0.8290\n",
      "Epoch 63/120\n",
      "10000/10000 [==============================] - 5s 478us/step - loss: 0.3036 - acc: 0.8722 - val_loss: 0.3651 - val_acc: 0.8210\n",
      "Epoch 64/120\n",
      "10000/10000 [==============================] - 3s 341us/step - loss: 0.2996 - acc: 0.8729 - val_loss: 0.3876 - val_acc: 0.8280\n",
      "Epoch 65/120\n",
      "10000/10000 [==============================] - 5s 463us/step - loss: 0.2947 - acc: 0.8753 - val_loss: 0.4329 - val_acc: 0.8130\n",
      "Epoch 66/120\n",
      "10000/10000 [==============================] - 3s 327us/step - loss: 0.2945 - acc: 0.8764 - val_loss: 0.4058 - val_acc: 0.8240\n",
      "Epoch 67/120\n",
      "10000/10000 [==============================] - 5s 465us/step - loss: 0.2908 - acc: 0.8789 - val_loss: 0.3896 - val_acc: 0.8260\n",
      "Epoch 68/120\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.2869 - acc: 0.8788 - val_loss: 0.4008 - val_acc: 0.8340\n",
      "Epoch 69/120\n",
      "10000/10000 [==============================] - 5s 484us/step - loss: 0.2851 - acc: 0.8793 - val_loss: 0.3913 - val_acc: 0.8220\n",
      "Epoch 70/120\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.2849 - acc: 0.8811 - val_loss: 0.4088 - val_acc: 0.8310\n",
      "Epoch 71/120\n",
      "10000/10000 [==============================] - 5s 461us/step - loss: 0.2848 - acc: 0.8791 - val_loss: 0.3986 - val_acc: 0.8220\n",
      "Epoch 72/120\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.2767 - acc: 0.8824 - val_loss: 0.3997 - val_acc: 0.8300\n",
      "Epoch 73/120\n",
      "10000/10000 [==============================] - 4s 414us/step - loss: 0.2785 - acc: 0.8803 - val_loss: 0.4020 - val_acc: 0.8220\n",
      "Epoch 74/120\n",
      "10000/10000 [==============================] - 5s 476us/step - loss: 0.2741 - acc: 0.8860 - val_loss: 0.3898 - val_acc: 0.8330\n",
      "Epoch 75/120\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.2770 - acc: 0.8832 - val_loss: 0.4227 - val_acc: 0.8340\n",
      "Epoch 76/120\n",
      "10000/10000 [==============================] - 5s 526us/step - loss: 0.2779 - acc: 0.8823 - val_loss: 0.4059 - val_acc: 0.8250\n",
      "Epoch 77/120\n",
      "10000/10000 [==============================] - 4s 354us/step - loss: 0.2809 - acc: 0.8810 - val_loss: 0.4102 - val_acc: 0.8260\n",
      "Epoch 78/120\n",
      "10000/10000 [==============================] - 5s 492us/step - loss: 0.2685 - acc: 0.8861 - val_loss: 0.4076 - val_acc: 0.8190\n",
      "Epoch 79/120\n",
      "10000/10000 [==============================] - 6s 647us/step - loss: 0.2673 - acc: 0.8858 - val_loss: 0.4033 - val_acc: 0.8310: 0s - loss: 0.2670 - \n",
      "Epoch 80/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.2701 - acc: 0.8845 - val_loss: 0.3932 - val_acc: 0.8260\n",
      "Epoch 81/120\n",
      "10000/10000 [==============================] - 7s 688us/step - loss: 0.2706 - acc: 0.8849 - val_loss: 0.4001 - val_acc: 0.8260\n",
      "Epoch 82/120\n",
      "10000/10000 [==============================] - 5s 470us/step - loss: 0.2710 - acc: 0.8856 - val_loss: 0.4547 - val_acc: 0.8190\n",
      "Epoch 83/120\n",
      "10000/10000 [==============================] - 5s 475us/step - loss: 0.2614 - acc: 0.8913 - val_loss: 0.4512 - val_acc: 0.8190\n",
      "Epoch 84/120\n",
      "10000/10000 [==============================] - 5s 493us/step - loss: 0.2616 - acc: 0.8894 - val_loss: 0.4209 - val_acc: 0.8280\n",
      "Epoch 85/120\n",
      "10000/10000 [==============================] - 5s 456us/step - loss: 0.2605 - acc: 0.8915 - val_loss: 0.4409 - val_acc: 0.8290\n",
      "Epoch 86/120\n",
      "10000/10000 [==============================] - 5s 478us/step - loss: 0.2616 - acc: 0.8926 - val_loss: 0.4273 - val_acc: 0.8250\n",
      "Epoch 87/120\n",
      "10000/10000 [==============================] - 5s 546us/step - loss: 0.2572 - acc: 0.8952 - val_loss: 0.4357 - val_acc: 0.8210\n",
      "Epoch 88/120\n",
      "10000/10000 [==============================] - 5s 527us/step - loss: 0.2518 - acc: 0.8925 - val_loss: 0.4356 - val_acc: 0.8140\n",
      "Epoch 89/120\n",
      "10000/10000 [==============================] - 4s 354us/step - loss: 0.2527 - acc: 0.8934 - val_loss: 0.4351 - val_acc: 0.8240\n",
      "Epoch 90/120\n",
      "10000/10000 [==============================] - 5s 467us/step - loss: 0.2548 - acc: 0.8951 - val_loss: 0.4666 - val_acc: 0.8240\n",
      "Epoch 91/120\n",
      "10000/10000 [==============================] - 5s 517us/step - loss: 0.2502 - acc: 0.8978 - val_loss: 0.4166 - val_acc: 0.8260\n",
      "Epoch 92/120\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2549 - acc: 0.8948 - val_loss: 0.4278 - val_acc: 0.8320\n",
      "Epoch 93/120\n",
      "10000/10000 [==============================] - 9s 869us/step - loss: 0.2475 - acc: 0.8963 - val_loss: 0.5118 - val_acc: 0.8140\n",
      "Epoch 94/120\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.2484 - acc: 0.8949 - val_loss: 0.4803 - val_acc: 0.8100\n",
      "Epoch 95/120\n",
      "10000/10000 [==============================] - 5s 491us/step - loss: 0.2449 - acc: 0.8964 - val_loss: 0.4797 - val_acc: 0.8240\n",
      "Epoch 96/120\n",
      "10000/10000 [==============================] - 4s 356us/step - loss: 0.2414 - acc: 0.8994 - val_loss: 0.4657 - val_acc: 0.8240\n",
      "Epoch 97/120\n",
      "10000/10000 [==============================] - 5s 511us/step - loss: 0.2410 - acc: 0.8985 - val_loss: 0.4502 - val_acc: 0.8140\n",
      "Epoch 98/120\n",
      "10000/10000 [==============================] - 4s 354us/step - loss: 0.2438 - acc: 0.9023 - val_loss: 0.4670 - val_acc: 0.8300\n",
      "Epoch 99/120\n",
      "10000/10000 [==============================] - 5s 492us/step - loss: 0.2378 - acc: 0.9009 - val_loss: 0.4892 - val_acc: 0.8150\n",
      "Epoch 100/120\n",
      "10000/10000 [==============================] - 4s 404us/step - loss: 0.2371 - acc: 0.9016 - val_loss: 0.5024 - val_acc: 0.8130\n",
      "Epoch 101/120\n",
      "10000/10000 [==============================] - 5s 453us/step - loss: 0.2391 - acc: 0.9007 - val_loss: 0.4780 - val_acc: 0.8190\n",
      "Epoch 102/120\n",
      "10000/10000 [==============================] - 5s 460us/step - loss: 0.2375 - acc: 0.9026 - val_loss: 0.5203 - val_acc: 0.8150\n",
      "Epoch 103/120\n",
      "10000/10000 [==============================] - 4s 395us/step - loss: 0.2347 - acc: 0.9030 - val_loss: 0.4917 - val_acc: 0.8240\n",
      "Epoch 104/120\n",
      "10000/10000 [==============================] - 6s 555us/step - loss: 0.2302 - acc: 0.9044 - val_loss: 0.4676 - val_acc: 0.8190\n",
      "Epoch 105/120\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.2336 - acc: 0.9022 - val_loss: 0.4583 - val_acc: 0.8200\n",
      "Epoch 106/120\n",
      "10000/10000 [==============================] - 5s 474us/step - loss: 0.2322 - acc: 0.9069 - val_loss: 0.4812 - val_acc: 0.8200\n",
      "Epoch 107/120\n",
      "10000/10000 [==============================] - 3s 345us/step - loss: 0.2276 - acc: 0.9060 - val_loss: 0.4778 - val_acc: 0.8250\n",
      "Epoch 108/120\n",
      "10000/10000 [==============================] - 5s 531us/step - loss: 0.2282 - acc: 0.9053 - val_loss: 0.4596 - val_acc: 0.8220\n",
      "Epoch 109/120\n",
      "10000/10000 [==============================] - 5s 550us/step - loss: 0.2229 - acc: 0.9085 - val_loss: 0.4732 - val_acc: 0.8240\n",
      "Epoch 110/120\n",
      "10000/10000 [==============================] - 3s 349us/step - loss: 0.2304 - acc: 0.9076 - val_loss: 0.5126 - val_acc: 0.8260\n",
      "Epoch 111/120\n",
      "10000/10000 [==============================] - 5s 486us/step - loss: 0.2261 - acc: 0.9050 - val_loss: 0.5204 - val_acc: 0.8220\n",
      "Epoch 112/120\n",
      "10000/10000 [==============================] - 4s 350us/step - loss: 0.2230 - acc: 0.9084 - val_loss: 0.5359 - val_acc: 0.8230\n",
      "Epoch 113/120\n",
      "10000/10000 [==============================] - 5s 477us/step - loss: 0.2194 - acc: 0.9094 - val_loss: 0.5393 - val_acc: 0.8180\n",
      "Epoch 114/120\n",
      "10000/10000 [==============================] - 5s 468us/step - loss: 0.2199 - acc: 0.9091 - val_loss: 0.5019 - val_acc: 0.8210\n",
      "Epoch 115/120\n",
      "10000/10000 [==============================] - 6s 604us/step - loss: 0.2244 - acc: 0.9089 - val_loss: 0.4840 - val_acc: 0.8190\n",
      "Epoch 116/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 495us/step - loss: 0.2221 - acc: 0.9097 - val_loss: 0.4797 - val_acc: 0.8180\n",
      "Epoch 117/120\n",
      "10000/10000 [==============================] - 5s 500us/step - loss: 0.2181 - acc: 0.9088 - val_loss: 0.5423 - val_acc: 0.8220\n",
      "Epoch 118/120\n",
      "10000/10000 [==============================] - 4s 445us/step - loss: 0.2140 - acc: 0.9105 - val_loss: 0.5114 - val_acc: 0.8250\n",
      "Epoch 119/120\n",
      "10000/10000 [==============================] - 4s 416us/step - loss: 0.2205 - acc: 0.9102 - val_loss: 0.4851 - val_acc: 0.8200\n",
      "Epoch 120/120\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.2134 - acc: 0.9135 - val_loss: 0.4750 - val_acc: 0.8280\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([inputs_train, queries_train], answer_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answer_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('brandnewmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('chatbot_10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'John', 'in', 'the', 'kitchen', '?']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.6906323e-14, 5.5444087e-14, 5.7849457e-14, 5.3208103e-14,\n",
       "       6.1402157e-14, 5.4011381e-14, 9.9972337e-01, 6.5257363e-14,\n",
       "       5.5710580e-14, 5.3492204e-14, 5.5344767e-14, 5.9928089e-14,\n",
       "       5.9666451e-14, 6.2852745e-14, 4.7628341e-14, 6.1548721e-14,\n",
       "       5.2162844e-14, 5.4474047e-14, 4.9623598e-14, 2.7658895e-04,\n",
       "       5.7422701e-14, 5.4287968e-14, 6.0373690e-14, 5.7739004e-14,\n",
       "       5.4291698e-14, 5.7451846e-14, 5.6180521e-14, 5.9328946e-14,\n",
       "       4.7667968e-14, 5.7854315e-14, 6.1993372e-14, 5.1244934e-14,\n",
       "       4.9404684e-14, 5.6873343e-14, 6.2960250e-14, 6.8127443e-14,\n",
       "       5.0650619e-14, 5.7325963e-14], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(pred_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'up'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('john', 1), ('yes', 2), ('office', 3), ('?', 4), ('moved', 5), ('up', 6), ('mary', 7), ('back', 8), ('dropped', 9), ('in', 10), ('garden', 11), ('.', 12), ('got', 13), ('travelled', 14), ('left', 15), ('apple', 16), ('is', 17), ('picked', 18), ('journeyed', 19), ('football', 20), ('kitchen', 21), ('milk', 22), ('there', 23), ('down', 24), ('discarded', 25), ('daniel', 26), ('grabbed', 27), ('to', 28), ('the', 29), ('went', 30), ('took', 31), ('sandra', 32), ('bathroom', 33), ('no', 34), ('put', 35), ('bedroom', 36), ('hallway', 37)])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
